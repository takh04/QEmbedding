{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import sys\n",
    "sys.path.insert(0, '/Users/tak/Github/QEmbedding/')\n",
    "import Hybrid_nn\n",
    "import torch\n",
    "from torch import nn\n",
    "import data\n",
    "import pennylane as qml\n",
    "import embedding"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Getting Started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-18 20:53:22.688658: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 20:53:22.690102: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 10. Tune using inter_op_parallelism_threads for best performance.\n",
      "/opt/anaconda3/envs/QC/lib/python3.7/site-packages/ipykernel_launcher.py:10: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646835196/work/torch/csrc/utils/tensor_new.cpp:233.)\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "feature_reduction = 'PCA16'\n",
    "classes = [0,1]\n",
    "X_train, X_test, Y_train, Y_test = data.data_load_and_process('mnist', '2', feature_reduction=feature_reduction, classes=classes)\n",
    "X1_test, X0_test = [], []\n",
    "for i in range(len(X_test)):\n",
    "    if Y_test[i] == 1:\n",
    "        X1_test.append(X_test[i])\n",
    "    else:\n",
    "        X0_test.append(X_test[i])\n",
    "X1_test, X0_test = torch.tensor(X1_test), torch.tensor(X0_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the Trace Distance Before training the embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/QC/lib/python3.7/site-packages/pennylane/qnn/torch.py:328: UserWarning: Casting complex values to real discards the imaginary part (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1666646835196/work/aten/src/ATen/native/Copy.cpp:250.)\n",
      "  return self.qnode(**kwargs).type(x.dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Distance before: 0.542850911617279\n",
      "\n",
      "Hilbert Schmidt distance before: 0.22676578164100647\n"
     ]
    }
   ],
   "source": [
    "dev = qml.device('default.qubit', wires=4)\n",
    "\n",
    "@qml.qnode(dev, interface=\"torch\")\n",
    "def distance_circuit1(inputs): \n",
    "    qml.AmplitudeEmbedding(inputs, wires=range(4), normalize=True)\n",
    "    return qml.density_matrix(wires=range(4))\n",
    "\n",
    "class Distance(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qlayer1_distance = qml.qnn.TorchLayer(distance_circuit1, weight_shapes={})\n",
    "    \n",
    "    def forward(self, x1, x0, measure):\n",
    "        rhos1 = self.qlayer1_distance(x1)\n",
    "        rhos0 = self.qlayer1_distance(x0)\n",
    "        rho1 = torch.sum(rhos1, dim=0) / len(x1)\n",
    "        rho0 = torch.sum(rhos0, dim=0) / len(x0)\n",
    "        rho_diff = rho1 - rho0\n",
    "\n",
    "        if measure == \"Trace\":\n",
    "            eigvals = torch.linalg.eigvals(rho_diff)\n",
    "            return 0.5 * torch.real(torch.sum(torch.abs(eigvals)))\n",
    "        elif measure == \"Hilbert-Schmidt\":\n",
    "            return 0.5 * torch.real(torch.trace(rho_diff @ rho_diff))\n",
    "        \n",
    "\n",
    "D = Distance()\n",
    "D_trace = D(X1_test, X0_test, \"Trace\")\n",
    "D_HS = D(X1_test, X0_test, \"Hilbert-Schmidt\")\n",
    "print(f\"Trace Distance before: {D_trace}\\n\")\n",
    "print(f\"Hilbert Schmidt distance before: {D_HS}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Distances After the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distance_After(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.qlayer1_distance = qml.qnn.TorchLayer(distance_circuit1, weight_shapes={})\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x1, x0, measure):\n",
    "        x1 = self.linear_relu_stack(x1)\n",
    "        x0 = self.linear_relu_stack(x0)\n",
    "        rhos1 = self.qlayer1_distance(x1)\n",
    "        rhos0 = self.qlayer1_distance(x0)\n",
    "        rho1 = torch.sum(rhos1, dim=0) / len(x1)\n",
    "        rho0 = torch.sum(rhos0, dim=0) / len(x0)\n",
    "        rho_diff = rho1 - rho0\n",
    "\n",
    "        if measure == \"Trace\":\n",
    "            eigvals = torch.linalg.eigvals(rho_diff)\n",
    "            return 0.5 * torch.real(torch.sum(torch.abs(eigvals)))\n",
    "        elif measure == \"Hilbert-Schmidt\":\n",
    "            return 0.5 * torch.real(torch.trace(rho_diff @ rho_diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trace Distance After training with Model_Amplitude: 0.9526245474815369 ± 0.001617120687990123\n",
      "Hilbert Schmidt distance After training with Model_Amplitude: 0.8807974100112915 ± 0.006995544806932898\n"
     ]
    }
   ],
   "source": [
    "Model_Amplitude_PATH = []\n",
    "for i in range(5):\n",
    "    Model_Amplitude_PATH.append(f\"/Users/tak/Github/QEmbedding/Results/earlystop 10 experiments/experiment{i+1}/Model Amplitude/Model_Amplitude.pt\")\n",
    "\n",
    "Model_Amplitude_Trace_Distances, Model_Amplitude_HS_Distances = np.array([]), np.array([])\n",
    "for path in Model_Amplitude_PATH:\n",
    "    Model = Distance_After()\n",
    "    Model.load_state_dict(torch.load(path, map_location=torch.device('cpu')))\n",
    "    with torch.no_grad():\n",
    "        trace_distance = Model(X1_test, X0_test, 'Trace')\n",
    "        HS_distance = Model(X1_test, X0_test, 'Hilbert-Schmidt')\n",
    "    Model_Amplitude_Trace_Distances = np.append(Model_Amplitude_Trace_Distances, trace_distance)\n",
    "    Model_Amplitude_HS_Distances = np.append(Model_Amplitude_HS_Distances, HS_distance)\n",
    "print(f\"Trace Distance After training with Model_Amplitude: {Model_Amplitude_Trace_Distances.mean()} ± {Model_Amplitude_Trace_Distances.std()}\")\n",
    "print(f\"Hilbert Schmidt distance After training with Model_Amplitude: {Model_Amplitude_HS_Distances.mean()} ± {Model_Amplitude_HS_Distances.std()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15 (default, Nov 24 2022, 12:02:37) \n[Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "18c4b2c9b6e0880abfbec0f1d78bbd37383c13120437ebae8d1a7afe7b354d80"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
